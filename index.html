<!DOCTYPE html>
<html lang="en">
<head>
<script>document.documentElement.classList.add('ivt-preboot');</script>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>In Vitro</title>
<link rel="icon" href="https://github.com/invitromedialab/invitromedialab.github.io/blob/main/imgs/00320-4177656063.png?raw=true" type="image/png"> 
<link rel="stylesheet" href="assets/css/main.css">
<style>
  * { margin: 0; padding: 0; box-sizing: border-box; }
  html, body { height: 100%; overflow: hidden; font-family: 'Verdana Pro Regular', Verdana, sans-serif; }
  #glCanvas { position: fixed; inset: 0; width: 100vw; height: 100vh; display: block; }
  .work-image,.work-video { display: none !important; }
  video#audioVideo { position:absolute; width:1px; height:1px; opacity:0; pointer-events:none; }
</style>
</head>
<body>

<canvas id="glCanvas"></canvas>

<!-- 音源：你的 MP4（仅音轨/黑画面也可） -->
<video id="audioVideo"
       src="sounds/sound1.mp4"
       preload="auto"
       playsinline
       controls="false"></video>

<!-- 隐藏占位：给 main.js 初始化菜单 -->
<video class="work-video" muted playsinline></video>
<img class="work-image" alt="hidden placeholder">

<!-- 占位配置 -->
<script id="page-media-config" type="application/json">
{
  "startIndex": 0,
  "transitionMs": 500,
  "media": [
    { "type": "image", "src": "data:image/gif;base64,R0lGODlhAQABAAAAACwAAAAAAQABAAA=" }
  ]
}
</script>

<script>
/* ===== 渐入/渐出控制器，暴露 window.Fade ===== */
(() => {
  let value=0, rafId=null, anim=null;
  const listeners=new Set();
  function apply(v){
    value=Math.max(0,Math.min(1,v));
    window.dispatchEvent(new CustomEvent('fadeprogress',{detail:{value}}));
    listeners.forEach(cb=>{try{cb(value)}catch(_){}}); 
    window.FADE_PROGRESS=value;
  }
  function tick(t){
    if(!anim)return;
    const {start,duration,from,to}=anim;
    const k=duration>0?Math.min(1,(t-start)/duration):1;
    const eased=k<.5?2*k*k:1-Math.pow(-2*k+2,2)/2;
    apply(from+(to-from)*eased);
    if(k>=1){anim=null;rafId=null;return;}
    rafId=requestAnimationFrame(tick);
  }
  function animateTo(target,ms){
    cancelAnimationFrame(rafId);anim=null;
    anim={from:value,to:Math.max(0,Math.min(1,target)),duration:Math.max(0,ms|0),start:performance.now()};
    rafId=requestAnimationFrame(tick);
  }
  window.Fade={
    get value(){return value;},
    set(v){cancelAnimationFrame(rafId);anim=null;apply(v);},
    fadeIn(ms=1200){animateTo(1,ms);},
    fadeOut(ms=1200){animateTo(0,ms);},
    onChange(cb){if(typeof cb==='function')listeners.add(cb);return()=>listeners.delete(cb);}
  };
  apply(0);
  window.addEventListener('load',()=>window.Fade.fadeIn(4200));
})();
</script>

<script>
let gl, shaderProgram, positionBuffer;
let uTimeLocation, uResolutionLocation, uMouseLocation, uFadeLocation, uAudioLocation;
let texture1, texture2, uTexture1Location, uTexture2Location;
let mousePos={x:0,y:0}; 
let canvas=document.getElementById('glCanvas');

/* ========= 音频（点击后开始 + 1s 渐入） ========= */
const VIDEO = document.getElementById('audioVideo');

let audioCtx = null, analyser = null, freqData = null, audioLevel = 0;
let mediaSourceNode = null, gainNode = null;
let audioWired = false;    // 是否已把 <video> 接入 WebAudio
let started = false;       // 是否已经启动过（只启一次）

async function startAudioOnGesture(){
  if(started) return;
  started = true;

  try{
    // 1) 创建/恢复 AudioContext（手势中允许）
    audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
    if(audioCtx.state === 'suspended') await audioCtx.resume();

    // 2) 节点：MediaElementSource -> Gain -> (Analyser & Destination)
    if(!mediaSourceNode) mediaSourceNode = audioCtx.createMediaElementSource(VIDEO);
    if(!gainNode){
      gainNode = audioCtx.createGain();
      gainNode.gain.setValueAtTime(0.0, audioCtx.currentTime); // 渐入从 0 开始
    }
    if(!analyser){
      analyser = audioCtx.createAnalyser();
      analyser.fftSize = 1024;
      analyser.smoothingTimeConstant = 0.85;
      freqData = new Uint8Array(analyser.frequencyBinCount);
    }

    if(!audioWired){
      mediaSourceNode.connect(gainNode);
      gainNode.connect(analyser);
      gainNode.connect(audioCtx.destination);
      audioWired = true;
    }

    // 3) 配置视频并播放（只播一次）
    VIDEO.loop = false;
    VIDEO.muted = false;       // 现在在手势中解静音
    VIDEO.volume = 1.0;        // 音量全开，渐入用 gainNode 完成
    // 从头播放（如果你想保持当前位置，可移除这一行）
    try { VIDEO.currentTime = 0; } catch(_) {}
    await VIDEO.play();

    // 4) 线性渐入 1 秒（更稳的做法，用音频图里的 gain）
    const now = audioCtx.currentTime;
    gainNode.gain.cancelScheduledValues(now);
    gainNode.gain.setValueAtTime(0.0, now);
    gainNode.gain.linearRampToValueAtTime(1.0, now + 1.0);

  }catch(e){
    console.warn('Start audio failed:', e);
  }
}

// 绑定一次性用户手势（点击/触摸/按键任意其一）
(function bindOneTimeGesture(){
  const once = async () => {
    await startAudioOnGesture();
    window.removeEventListener('pointerdown', once);
    window.removeEventListener('keydown', once);
    window.removeEventListener('touchstart', once);
  };
  window.addEventListener('pointerdown', once, {once:true});
  window.addEventListener('keydown', once, {once:true});
  window.addEventListener('touchstart', once, {once:true});
})();

// 每帧计算音频强度（低中频平均 + 二次平滑）
function updateAudioLevel(){
  if(!analyser || !freqData) return audioLevel;
  analyser.getByteFrequencyData(freqData);
  const bins = freqData.length;
  const i0 = Math.floor(bins*0.03);   // ~80Hz
  const i1 = Math.floor(bins*0.40);   // ~1kHz
  let sum = 0, cnt = 0;
  for(let i=i0;i<i1;i++){ sum += freqData[i]; cnt++; }
  const avg = cnt>0 ? (sum/cnt)/255 : 0;
  const target = Math.max(0, Math.min(1, avg));
  const SMOOTH = 0.15;                 // 二次指数平滑
  audioLevel += (target - audioLevel) * SMOOTH;
  return audioLevel;
}

// 结束后，能量缓慢衰减到 0
VIDEO.addEventListener('ended', () => {
  const decay = () => {
    audioLevel += (0 - audioLevel) * 0.10;
    if (audioLevel > 0.001) requestAnimationFrame(decay);
  };
  decay();
});

/* ========= 鼠标 & 触控 ========= */
canvas.addEventListener('mousemove',(e)=>{
  const rect=canvas.getBoundingClientRect();
  mousePos.x=e.clientX-rect.left;
  mousePos.y=rect.height-(e.clientY-rect.top);
});
canvas.addEventListener('touchmove',handleTouchMove,{passive:false});
window.addEventListener('resize',resizeCanvas,false);

function resizeCanvas(){
  canvas.width=window.innerWidth;
  canvas.height=window.innerHeight;
  if(gl) gl.viewport(0,0,canvas.width,canvas.height);
}
function handleTouchMove(event){
  event.preventDefault();
  if(event.touches.length>0){
    const touch=event.touches[0];
    const rect=canvas.getBoundingClientRect();
    mousePos.x=touch.clientX-rect.left;
    mousePos.y=rect.height-(touch.clientY-rect.top);
  }
}

/* ========= WebGL ========= */
function initWebGL(){
  gl=canvas.getContext('webgl2');
  canvas.width=window.innerWidth;
  canvas.height=window.innerHeight;
  if(!gl){ alert('WebGL2 不支持'); return; }

  const vertexShaderSource=`#version 300 es
  in vec4 aVertexPosition;
  out highp vec2 vTextureCoord;
  void main(){
    gl_Position=aVertexPosition;
    vTextureCoord=aVertexPosition.xy*0.5+0.5;
  }`;

  const fragmentShaderSource=`#version 300 es
  precision mediump float;
  in vec4 aVertexPosition;
  out vec4 fragColor;
  in highp vec2 vTextureCoord;
  uniform vec2 uMouse;
  uniform float uTime;
  uniform vec2 u_resolution;
  uniform sampler2D uTexture1;
  uniform sampler2D uTexture2;
  uniform float uFade;
  uniform float uAudio;   // 0..1

  float f(vec3 p){
    p.z += uTime/10.0;
    vec2 mouse = vec2(uMouse.x/u_resolution.x - 0.5, uMouse.y/u_resolution.y);
    p.xy += mouse.xy * 5.0;
    return length(cos(p*2.0) + 0.6*sin(p.x + uTime/2.0) + 0.03*cos((p.x*p.y+uTime))) - 0.4; 
  }
  void main(){
    float Fade = 1.0 - uFade;
    float rect = u_resolution.x / u_resolution.y;
    vec2 I = vec2(vTextureCoord.x*rect, vTextureCoord.y);
    vec3 d = 0.5 - vec3(I, 1.0);
    vec3 o = d;
    float audioBoost = mix(1.00, 0.35, clamp(uAudio, 0.0, 1.0));
    for(int i=0;i<15;i++){
     o-=f(o)*d*0.45*uFade*audioBoost;
    }
    vec4 c=vec4(0.6+Fade*3.,1.0,1.4-Fade,1.0); 
    c=abs(f(o-d)*c+f(o-0.4)*(vec4(2.0,2.2,2.3,1.)-c))*(1.-.3*o.z)*0.3;
    c.rgb += vec3(0.25, -0.14, 0.21) * uAudio; // 轻微颜色听感偏移
    fragColor = vec4(c.rgb * uFade, 1.0);
  }`;

  const vertexShader=createShader(gl,gl.VERTEX_SHADER,vertexShaderSource);
  const fragmentShader=createShader(gl,gl.FRAGMENT_SHADER,fragmentShaderSource);
  shaderProgram=createShaderProgram(gl,vertexShader,fragmentShader);

  uTimeLocation=gl.getUniformLocation(shaderProgram,'uTime');
  uResolutionLocation=gl.getUniformLocation(shaderProgram,'u_resolution');
  uMouseLocation=gl.getUniformLocation(shaderProgram,'uMouse');
  uFadeLocation=gl.getUniformLocation(shaderProgram,'uFade');
  uAudioLocation=gl.getUniformLocation(shaderProgram,'uAudio');
  uTexture1Location=gl.getUniformLocation(shaderProgram,'uTexture1');
  uTexture2Location=gl.getUniformLocation(shaderProgram,'uTexture2');

  positionBuffer=gl.createBuffer(); 
  gl.bindBuffer(gl.ARRAY_BUFFER,positionBuffer);
  const positions=[ 1.0, 1.0,  -1.0, 1.0,   1.0,-1.0,  -1.0,-1.0 ];
  gl.bufferData(gl.ARRAY_BUFFER,new Float32Array(positions),gl.STATIC_DRAW);

  texture1=loadTexture('texture/1.jpg',gl.TEXTURE0);
  texture2=loadTexture('texture/2.png',gl.TEXTURE1);

  requestAnimationFrame(render);
}

function createShader(gl,type,source){
  const shader=gl.createShader(type);
  gl.shaderSource(shader,source);
  gl.compileShader(shader);
  if(!gl.getShaderParameter(shader,gl.COMPILE_STATUS)){
    alert('着色器编译失败:'+gl.getShaderInfoLog(shader));
    gl.deleteShader(shader); return null;
  }
  return shader;
}
function createShaderProgram(gl,vs,fs){
  const prog=gl.createProgram();
  gl.attachShader(prog,vs);
  gl.attachShader(prog,fs);
  gl.linkProgram(prog);
  if(!gl.getProgramParameter(prog,gl.LINK_STATUS)){
    alert('无法初始化着色器程序:'+gl.getProgramInfoLog(prog));
    return null;
  }
  return prog;
}
function loadTexture(url,unit){
  const tex=gl.createTexture();
  gl.activeTexture(unit);
  gl.bindTexture(gl.TEXTURE_2D,tex);
  gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,1,1,0,gl.RGBA,gl.UNSIGNED_BYTE,new Uint8Array([0,0,255,255]));
  const img=new Image();
  img.crossOrigin='anonymous';
  img.onload=function(){
    gl.bindTexture(gl.TEXTURE_2D,tex);
    gl.texImage2D(gl.TEXTURE_2D,0,gl.RGBA,gl.RGBA,gl.UNSIGNED_BYTE,img);
    gl.texParameteri(gl.TEXTURE_2D,gl.TEXTURE_MIN_FILTER,gl.LINEAR_MIPMAP_LINEAR);
    gl.texParameteri(gl.TEXTURE_2D,gl.TEXTURE_MAG_FILTER,gl.LINEAR);
    gl.generateMipmap(gl.TEXTURE_2D);
  };
  img.src=url;
  return tex;
}

function render(now){
  now/=1000.0;
  gl.useProgram(shaderProgram);

  const posLoc=gl.getAttribLocation(shaderProgram,'aVertexPosition');
  gl.enableVertexAttribArray(posLoc);
  gl.bindBuffer(gl.ARRAY_BUFFER,positionBuffer);
  gl.vertexAttribPointer(posLoc,2,gl.FLOAT,false,0,0);

  const level = updateAudioLevel();

  gl.uniform2f(uResolutionLocation,gl.canvas.width,gl.canvas.height);
  gl.uniform1f(uTimeLocation,now);
  gl.uniform2f(uMouseLocation,mousePos.x,mousePos.y);
  gl.uniform1f(uFadeLocation, window.Fade?.value ?? 1.0);
  gl.uniform1f(uAudioLocation, level);

  gl.activeTexture(gl.TEXTURE0); gl.bindTexture(gl.TEXTURE_2D,texture1); gl.uniform1i(uTexture1Location,0);
  gl.activeTexture(gl.TEXTURE1); gl.bindTexture(gl.TEXTURE_2D,texture2); gl.uniform1i(uTexture2Location,1);

  gl.viewport(0,0,gl.canvas.width,gl.canvas.height);
  gl.clear(gl.COLOR_BUFFER_BIT);
  gl.drawArrays(gl.TRIANGLE_STRIP,0,4);

  requestAnimationFrame(render);
}

/* ========= 事件绑定 ========= */
window.addEventListener('resize',resizeCanvas,false);
function init(){
  resizeCanvas();
  initWebGL();
}
window.addEventListener('load', init);

/* ========= 鼠标/触控位置 ========= */
canvas.addEventListener('mousemove',(e)=>{
  const rect=canvas.getBoundingClientRect();
  mousePos.x=e.clientX-rect.left;
  mousePos.y=rect.height-(e.clientY-rect.top);
});
canvas.addEventListener('touchmove',handleTouchMove,{passive:false});
function handleTouchMove(event){
  event.preventDefault();
  if(event.touches.length>0){
    const touch=event.touches[0];
    const rect=canvas.getBoundingClientRect();
    mousePos.x=touch.clientX-rect.left;
    mousePos.y=rect.height-(touch.clientY-rect.top);
  }
}
</script>

<!-- 注入菜单 -->
<script src="assets/js/main.js" defer></script>
</body>
</html>
