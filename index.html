<!DOCTYPE html>
<html lang="en">
<head>
  <script>document.documentElement.classList.add('ivt-preboot');</script>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover" />
  <title>In Vitro</title>
  <link rel="icon" href="imgs/icon/icon.png" type="image/png">
  <link rel="stylesheet" href="assets/css/main.css">
  <style>
    *{margin:0;padding:0;box-sizing:border-box}
    html,body{height:100%;overflow:hidden;font-family:'Verdana Pro Regular',Verdana,sans-serif;background:#000}
    #glCanvas{position:fixed;inset:0;width:100vw;height:100vh;display:block}
    .work-image,.work-video{display:none!important}
    audio#bgm{position:absolute;width:1px;height:1px;opacity:0;pointer-events:none}
    /* 首击透明接手层 */
    #tapgate{position:fixed;inset:0;z-index:999999;background:transparent;cursor:pointer}
  </style>
</head>
<body>

<!-- 首次点击接手层：确保首击动作被我们捕获 -->
<div id="tapgate" aria-label="tap-to-start"></div>

<canvas id="glCanvas"></canvas>

<!-- MP3 音源：同域或正确CORS；确保 MIME 为 audio/mpeg -->
<audio id="bgm" src="sounds/sound1.mp3" preload="auto" playsinline></audio>

<!-- 隐藏占位：给 main.js 初始化菜单 -->
<video class="work-video" muted playsinline></video>
<img class="work-image" alt="hidden placeholder">

<script id="page-media-config" type="application/json">
{
  "startIndex": 0,
  "transitionMs": 500,
  "media": [{ "type": "image", "src": "data:image/gif;base64,R0lGODlhAQABAAAAACwAAAAAAQABAAA=" }]
}
</script>

<!-- ===== 全局画面淡入/淡出控制 ===== -->
<script>
(() => {
  let value=0, rafId=null, anim=null;
  const listeners=new Set();
  function apply(v){
    value=Math.max(0,Math.min(1,v));
    window.dispatchEvent(new CustomEvent('fadeprogress',{detail:{value}}));
    listeners.forEach(cb=>{try{cb(value)}catch(_){}}); 
    window.FADE_PROGRESS=value;
  }
  function tick(t){
    if(!anim) return;
    const {start,duration,from,to}=anim;
    const k=duration>0?Math.min(1,(t-start)/duration):1;
    const eased=k<.5?2*k*k:1-Math.pow(-2*k+2,2)/2;
    apply(from+(to-from)*eased);
    if(k>=1){anim=null;rafId=null;return;}
    rafId=requestAnimationFrame(tick);
  }
  function animateTo(target,ms){
    cancelAnimationFrame(rafId); anim=null;
    anim={from:value,to:Math.max(0,Math.min(1,target)),duration:Math.max(0,ms|0),start:performance.now()};
    rafId=requestAnimationFrame(tick);
  }
  window.Fade={
    get value(){return value;},
    set(v){cancelAnimationFrame(rafId);anim=null;apply(v);},
    fadeIn(ms=1200){animateTo(1,ms);},
    fadeOut(ms=1200){animateTo(0,ms);},
    onChange(cb){if(typeof cb==='function')listeners.add(cb);return()=>listeners.delete(cb);}
  };
  apply(0);
  window.addEventListener('load',()=>window.Fade.fadeIn(4200));
})();
</script>

<!-- ===== 音频首击必响 + 兜底、导航淡出、频谱 ===== -->
<script>
/* ===== 全局状态 ===== */
let gl, shaderProgram, positionBuffer;
let uTimeLocation, uResolutionLocation, uMouseLocation, uFadeLocation, uAudioLocation;
let texture1, texture2, uTexture1Location, uTexture2Location;
let mousePos={x:0,y:0};
const canvas=document.getElementById('glCanvas');

/* ===== 音频对象 ===== */
const AUDIO = document.getElementById('bgm');
let audioCtx=null, analyser=null, gainNode=null, mediaSourceNode=null, freqData=null;
let wired=false, started=false, usingBufferFallback=false;
let bufferNode=null, decodedBuffer=null;

/* ★ 重要修正：移除“静音预热 IIFE”和任何在手势之前触发的 play()/AudioContext 创建。
   —— 这样就不会再出现：
   The AudioContext was not allowed to start... 的报错 */

/* ★ decode 改为仅在已有 audioCtx 时使用；不在函数内部创建 AudioContext */
async function decodeOnceToBuffer(ctx) {
  if (decodedBuffer) return decodedBuffer;
  if (!ctx) throw new Error('AudioContext not ready');
  const res = await fetch(AUDIO.src, { cache: 'force-cache' });
  const arr = await res.arrayBuffer();
  decodedBuffer = await ctx.decodeAudioData(arr);
  return decodedBuffer;
}

/* 建立音频图（仅在用户手势后调用） */
function ensureAudioGraph(){
  if (!audioCtx) audioCtx = new (window.AudioContext||window.webkitAudioContext)(); // ★ 手势后才会运行
  if (!gainNode) {
    gainNode = audioCtx.createGain();
    gainNode.gain.setValueAtTime(0.0, audioCtx.currentTime);
  }
  if (!analyser) {
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 1024;
    analyser.smoothingTimeConstant = 0.85;
    freqData = new Uint8Array(analyser.frequencyBinCount);
  }
  if (!mediaSourceNode) mediaSourceNode = audioCtx.createMediaElementSource(AUDIO);
  if (!wired) {
    mediaSourceNode.connect(gainNode);
    gainNode.connect(analyser);
    gainNode.connect(audioCtx.destination);
    wired = true;
  }
}

/* 元素路径播放（等待成功/失败）——仅手势后调用 */
async function tryPlayViaElementOnce(){
  ensureAudioGraph();
  if (audioCtx.state === 'suspended') await audioCtx.resume();

  AUDIO.muted = false;            // 可根据需要保留静音
  AUDIO.loop  = false;
  try { AUDIO.currentTime = 0; } catch(_) {}

  const p = AUDIO.play();
  if (p && typeof p.then === 'function') await p;
}

/* WebAudio Buffer 兜底（仍在同一次手势中触发） */
async function playViaBufferFallback(){
  usingBufferFallback = true;
  ensureAudioGraph();
  if (audioCtx.state === 'suspended') await audioCtx.resume();

  // 停掉旧的
  if (bufferNode) {
    try { bufferNode.stop(); } catch(_) {}
    try { bufferNode.disconnect(); } catch(_) {}
    bufferNode = null;
  }
  const buf = await decodeOnceToBuffer(audioCtx);  // ★ 传入现有 ctx
  bufferNode = audioCtx.createBufferSource();
  bufferNode.buffer = buf;
  bufferNode.loop = false;
  bufferNode.connect(gainNode);
  bufferNode.start();
}

/* 首击接手：强占第一次用户手势，保证同步链路 */
(function installFirstTapGate(){
  const gate = document.getElementById('tapgate');

  const onFirstTap = async (ev) => {
    ev.preventDefault();
    if (started) { gate.remove(); return; }
    started = true;

    try{
      // ★ 所有与音频有关的动作都放在手势回调里
      let ok = true;
      try {
        await tryPlayViaElementOnce();
      } catch (e) {
        ok = false;
      }
      if (!ok) {
        await playViaBufferFallback();
      }

      // 音量淡入
      const now = audioCtx.currentTime;
      gainNode.gain.cancelScheduledValues(now);
      gainNode.gain.setValueAtTime(0.0, now);
      gainNode.gain.linearRampToValueAtTime(1.0, now + 1.0);

      gate.remove();
    } catch (e) {
      console.warn('Audio unlock failed:', e);
      started = false; // 允许再次尝试
      // 不移除 gate，让用户能再点一次
    }
  };

  // 多重保险：pointerdown / touchend / keydown
  gate.addEventListener('pointerdown', onFirstTap, { once:true });
  gate.addEventListener('touchend',   onFirstTap, { once:true, passive:false });
  window.addEventListener('keydown',  onFirstTap, { once:true });
})();

/* 可选兜底：返回前台时再尝试一次解锁（仅当之前失败过） */
document.addEventListener('visibilitychange', async () => {
  if (document.visibilityState === 'visible' && audioCtx && audioCtx.state !== 'running') {
    try { await audioCtx.resume(); } catch(_){}
  }
});

/* 导航时：画面+音频 同步淡出后再跳转 */
const NAV_FADE_OUT_MS = 1000;
function installNavAudioFadeOut(ms = NAV_FADE_OUT_MS){
  function findAnchor(el){
    while(el && el !== document){
      if(el.tagName === 'A' && el.href) return el;
      el = el.parentElement;
    }
    return null;
  }
  document.addEventListener('click', (e) => {
    if (e.defaultPrevented) return;
    if (e.button !== 0) return;
    if (e.metaKey || e.ctrlKey || e.shiftKey || e.altKey) return;

    const a = findAnchor(e.target);
    if(!a) return;

    const href = a.getAttribute('href');
    if(!href || href.startsWith('#') || href.startsWith('javascript:')) return;
    const tgt = a.getAttribute('target');
    if (tgt && tgt !== '' && tgt !== '_self') return;

    e.preventDefault();

    try { window.Fade?.fadeOut(ms); } catch(_) {}

    if (gainNode && audioCtx){
      try{
        const now = audioCtx.currentTime;
        gainNode.gain.cancelScheduledValues(now);
        gainNode.gain.setValueAtTime(gainNode.gain.value, now);
        gainNode.gain.linearRampToValueAtTime(0.0, now + ms/1000);
      }catch(_){}
    }
    setTimeout(() => { window.location.href = a.href; }, ms);
  }, true);
}
window.fadeOutAllThen = function(nextHref, ms = NAV_FADE_OUT_MS){
  if(!nextHref) return;
  try { window.Fade?.fadeOut(ms); } catch(_) {}
  if (gainNode && audioCtx){
    try{
      const now = audioCtx.currentTime;
      gainNode.gain.cancelScheduledValues(now);
      gainNode.gain.setValueAtTime(gainNode.gain.value, now);
      gainNode.gain.linearRampToValueAtTime(0.0, now + ms/1000);
    }catch(_){}
  }
  setTimeout(() => { window.location.href = nextHref; }, ms);
};
installNavAudioFadeOut();

/* 频谱电平（uAudio） */
let audioLevel = 0;
function updateAudioLevel(){
  if(!analyser || !freqData) return audioLevel;
  analyser.getByteFrequencyData(freqData);
  const bins = freqData.length;
  const i0 = Math.floor(bins*0.03);   // ~80Hz
  const i1 = Math.floor(bins*0.40);   // ~1kHz
  let sum=0,cnt=0; for(let i=i0;i<i1;i++){ sum+=freqData[i]; cnt++; }
  const avg = cnt? (sum/cnt)/255 : 0;
  const target = Math.max(0, Math.min(1, avg));
  const SMOOTH = 0.15;
  audioLevel += (target - audioLevel) * SMOOTH;
  return audioLevel;
}
AUDIO.addEventListener('ended', () => {
  const decay = () => {
    audioLevel += (0 - audioLevel) * 0.10;
    if (audioLevel > 0.001) requestAnimationFrame(decay);
  };
  decay();
});

/* ====== 全局指针跟踪（capture 阶段；tapgate 在时也能拿到） ====== */
const onPointerMove = (x,y,rect) => {
  mousePos.x = x - rect.left;
  mousePos.y = rect.height - (y - rect.top);
};
(function bindGlobalPointerTracking(){
  const move = (e) => {
    const t = (e.touches && e.touches[0]) ? e.touches[0] : e;
    const rect = canvas.getBoundingClientRect();
    onPointerMove(t.clientX, t.clientY, rect);
  };
  const opts = { passive: false, capture: true };

  document.addEventListener('pointermove', move, opts);
  document.addEventListener('touchmove',   move, opts);

  const gate = document.getElementById('tapgate');
  if (gate) {
    gate.addEventListener('pointermove', move, opts);
    gate.addEventListener('touchmove',   move, opts);
  }

  canvas.addEventListener('pointermove', move, opts);
  canvas.addEventListener('touchmove',   move, opts);
})();

window.addEventListener('resize',()=>resizeCanvas(),false);
</script>

<!-- ===== WebGL（保持你的着色器逻辑） ===== -->
<script>
function initWebGL(){
  const gl2 = canvas.getContext('webgl2');
  if(!gl2){ alert('WebGL2 不支持'); return; }
  gl = gl2;
  resizeCanvas();

  const vertexShaderSource=`#version 300 es
  in vec4 aVertexPosition;
  out highp vec2 vTextureCoord;
  void main(){ gl_Position=aVertexPosition; vTextureCoord=aVertexPosition.xy+.5; }`;

  const fragmentShaderSource=`#version 300 es
  precision mediump float;
  in vec4 aVertexPosition;
  out vec4 fragColor;
  in highp vec2 vTextureCoord;
  uniform vec2 uMouse;
  uniform float uTime;
  uniform vec2 u_resolution;

  uniform float uFade;
  uniform float uAudio;

  float f(vec3 p){
    p.z+=uTime/10.0;
    vec2 mouse=vec2(uMouse.x/u_resolution.x-0.5,uMouse.y/u_resolution.y);
    p.xy+=mouse.xy*5.;
    return length(cos(p*2.)+.6*sin(p.x+uTime/2.)+.03*cos((p.x*p.y+uTime)))-.4; 
  }
  void main(){
    float audioBoost = mix(1.0, 5.35, clamp(uAudio, 0.0, 1.0));
    float Fade = 1.0-uFade;
    float rect=u_resolution.x/u_resolution.y;
    vec2 I=vec2(vTextureCoord.x*rect,vTextureCoord.y);
    vec3 d=0.5-vec3(I,1.);
    vec3 o=d*audioBoost;
    for(int i=0;i<15;i++){ o-=f(o)*d*0.45*uFade; }
    vec4 c=vec4(0.6+Fade*3.,1.0,1.4-Fade,1.0);
    c=abs(f(o-d)*c+f(o-0.4)*(vec4(2.0,2.2,2.3,1.)-c))*(1.-.3*o.z)*0.3;
    c.rgb += vec3(0.27, -0.14, 0.22) * uAudio;
    fragColor=vec4(c.xyz*uFade,1.0);
  }`;

  const vs=createShader(gl,gl.VERTEX_SHADER,vertexShaderSource);
  const fs=createShader(gl,gl.FRAGMENT_SHADER,fragmentShaderSource);
  shaderProgram=createShaderProgram(gl,vs,fs);

  uTimeLocation=gl.getUniformLocation(shaderProgram,'uTime');
  uResolutionLocation=gl.getUniformLocation(shaderProgram,'u_resolution');
  uMouseLocation=gl.getUniformLocation(shaderProgram,'uMouse');
  uFadeLocation=gl.getUniformLocation(shaderProgram,'uFade');
  uAudioLocation=gl.getUniformLocation(shaderProgram,'uAudio');

  uTexture1Location = gl.getUniformLocation(shaderProgram, 'uTex1');
  uTexture2Location = gl.getUniformLocation(shaderProgram, 'uTex2');

  positionBuffer=gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER,positionBuffer);
  gl.bufferData(gl.ARRAY_BUFFER,new Float32Array([1,1,-1,1,1,-1,-1,-1]),gl.STATIC_DRAW);

  requestAnimationFrame(render);
}
function createShader(gl,type,source){
  const s=gl.createShader(type); gl.shaderSource(s,source); gl.compileShader(s);
  if(!gl.getShaderParameter(s,gl.COMPLETE_STATUS) && !gl.getShaderParameter(s,gl.COMPILE_STATUS)){
    alert('着色器编译失败:'+gl.getShaderInfoLog(s)); gl.deleteShader(s); return null;
  }
  return s;
}
function createShaderProgram(gl,vs,fs){
  const p=gl.createProgram(); gl.attachShader(p,vs); gl.attachShader(p,fs); gl.linkProgram(p);
  if(!gl.getProgramParameter(p,gl.LINK_STATUS)){ alert('无法初始化着色器程序:'+gl.getProgramInfoLog(p)); return null; }
  return p;
}
function render(now){
  now/=1000.0;
  gl.useProgram(shaderProgram);
  const posLoc=gl.getAttribLocation(shaderProgram,'aVertexPosition');
  gl.enableVertexAttribArray(posLoc);
  gl.bindBuffer(gl.ARRAY_BUFFER,positionBuffer);
  gl.vertexAttribPointer(posLoc,2,gl.FLOAT,false,0,0);

  const level = updateAudioLevel();

  gl.uniform2f(uResolutionLocation,gl.canvas.width,gl.canvas.height);
  gl.uniform1f(uTimeLocation,now);
  gl.uniform2f(uMouseLocation,mousePos.x,mousePos.y);
  gl.uniform1f(uFadeLocation, window.Fade?.value ?? 1.0);
  if(uAudioLocation) gl.uniform1f(uAudioLocation, level);

  gl.viewport(0,0,gl.canvas.width,gl.canvas.height);
  gl.clear(gl.COLOR_BUFFER_BIT);
  gl.drawArrays(gl.TRIANGLE_STRIP,0,4);

  requestAnimationFrame(render);
}
function resizeCanvas(){
  const dpr = Math.min(2, window.devicePixelRatio || 1);
  const w = Math.floor(window.innerWidth  * dpr);
  const h = Math.floor(window.innerHeight * dpr);
  if (canvas.width !== w || canvas.height !== h){
    canvas.width = w;
    canvas.height = h;
  }
  if(gl) gl.viewport(0,0,canvas.width,canvas.height);
}
window.addEventListener('load', ()=>{ resizeCanvas(); initWebGL(); }, {once:true});
window.addEventListener('resize', resizeCanvas);
</script>

<!-- 注入菜单（如果有站内导航） -->
<script src="assets/js/main.js" defer></script>
</body>
</html>
